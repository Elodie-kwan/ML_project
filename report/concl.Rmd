
```{r, echo = FALSE, message = FALSE}
source("../scripts/setup.R")
```


### Conclusion: Final analysis of scores

#### Compare the model scores to select the most accurate one 

To recap, we studied the following models with a balanced dataset and using data splitting to avoid over-fitting:

1) Neural network, with an accuracy and balanced accuracy  of 1 
2) Naive Bayes, with an accuracy of 96.3% and balanced of 90,48%
3) Key Nearest Neighbor (K=2), with an accuracy and balanced accuracy of 1. We explained why this accuracy might be affect by the overlayed observations. 

Then we fitted the models on an unique dataset, to avoid the overlayed observations. 

4) Random Forest: The accuracy appeared to be equal to 1 as well
5) Random Forest with the 5 most important variables. As a result we obtain an accuracy of 98.55% with only 5 variable. 
6) Neural Network with unique bootstrapped dataset: Accuracy of 1
7) KNN (K=2): Accuracy of 95.89% and Balanced accuracy of 1

To conclude about the variable importance, the most recurrent one, the one that really impact and makes a difference in the classification is the pH: pH_B, pH_T, pH_P. Without this soil characteristic, the accuracy would not be that good. 

To sum up, all the models have an accuracy above 90%. Neural Network seems to perform very well, before and after the unique data set. Moreover we could use this model to deal with all the variables. However, we have to bear in mind the size of the data set and the overlayed observations. Overall the random forest model seems to also be a good model that can be used with fewer variables while keeping a high accuracy. 


#### Limitations of our model:

The main limitations come from our data set used to train the model and test it. Indeed, as we noticed during the EDA we have a lot of duplicate data for the **Sierra de Guadarrama** region, these data when not removed from the data set influence the accuracy of both the test set and the train set. It is obvious that the prediction of identical data leads to a good result. Moreover, even if we remove these duplicates, the fact that the sub samples were taken close to each other prevents us from having results that are representative of a real study that would be conducted with samples taken from more widely spaced areas. We therefore have a false good precision, since the values to predict are close to those used to train the model. Ideally we should use only one sub sample per sample for our model, but in this case we would be sorely lacking in data to train our model. 

### Future work:

In the analysis, we discovered a strong positive correlation between **Soil organic carbon** and **Phosphatase enzyme**. For the future analysis, it would be interesting to see the features and characteristics that influence these two variables. 

We found an interesting articles describing the effects of phosphate rock and organic inputs on soil organic carbon and acid phosphatase activity.

Title: **Soil Organic Carbon and Acid Phosphatase Enzyme Activity Response to Phosphate Rock and Organic Inputs in Acidic Soils of Central Highlands of Kenya in Maize**: <https://ir-library.ku.ac.ke/bitstream/handle/123456789/22271/Soil%20Organic%20Carbon%20and%20Acid%20Phosphatase%20Enzyme....pdf?sequence=1>


With more time an interesting study could be to look on the map if the samples were taken close to a watercourse by transforming this information into a binary variable. Then we can analyze if there is a correlation between the chemical elements of the soil and their proximity to a water point, independently of the region and the climate. Thus, depending on the result of this analysis, we will be able to specify the description of the quality of a sample in terms of its ability to predict a class. The operation could be repeated with the samples close to a forest, as well as with the altitude of sampling.  

